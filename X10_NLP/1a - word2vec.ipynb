{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"Ue5hxxkdAQJg"},"source":["<img src=\"https://github.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/raw/main/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n","\n","\n","# Procesamiento de lenguaje natural\n","## Vectorización\n"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"kCED1hh-Ioyf"},"outputs":[],"source":["import numpy as np"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"PUbfVnzIIoMj"},"outputs":[],"source":["def cosine_similarity(a, b):\n","    return np.dot(a, b) / (np.linalg.norm(a) * (np.linalg.norm(b)))"]},{"cell_type":"markdown","metadata":{"id":"DMOa4JPSCJ29"},"source":["### Datos"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"RIO7b8GjAC17"},"outputs":[],"source":["corpus = np.array(['que dia es hoy', 'martes el dia de hoy es martes', 'martes muchas gracias'])"]},{"cell_type":"markdown","metadata":{"id":"8WqdaTmO8P1r"},"source":["Documento 1 --> que dia es hoy \\\n","Documento 2 --> martes el dia de hoy es martes \\\n","Documento 3 --> martes muchas gracias"]},{"cell_type":"markdown","metadata":{"id":"FVHxBRNzCMOS"},"source":["### 1 - Obtener el vocabulario del corpus (los términos utilizados)\n","- Cada documento transformarlo en una lista de términos\n","- Armar un vector de términos no repetidos de todos los documentos"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"3ZqTOZzDI7uv"},"outputs":[{"name":"stdout","output_type":"stream","text":["Corpus: [['que', 'dia', 'es', 'hoy'], ['martes', 'el', 'dia', 'de', 'hoy', 'es', 'martes'], ['martes', 'muchas', 'gracias']]\n","Vocabulario: {'muchas', 'gracias', 'que', 'es', 'de', 'hoy', 'martes', 'el', 'dia'}\n"]}],"source":["docs = []\n","vocab = set()\n","for i in corpus:\n","    terminos = i.split(' ')\n","    docs.append(terminos)\n","    vocab.update(set(terminos))\n","\n","print(f'Corpus: {docs}')\n","print(f'Vocabulario: {vocab}')"]},{"cell_type":"markdown","metadata":{"id":"RUhH983FI7It"},"source":["### 2- OneHot encoding\n","Data una lista de textos, devolver una matriz con la representación oneHotEncoding de estos"]},{"cell_type":"code","execution_count":91,"metadata":{"id":"Os0AAQo6I6Z1"},"outputs":[{"name":"stdout","output_type":"stream","text":["[['que', 'dia', 'es', 'hoy'], ['martes', 'el', 'dia', 'de', 'hoy', 'es', 'martes'], ['martes', 'muchas', 'gracias']]\n","['muchas', 'gracias', 'que', 'es', 'de', 'hoy', 'martes', 'el', 'dia']\n","Matriz de vectores One Hot Encoding:\n","[[0. 0. 1. 1. 0. 1. 0. 0. 1.]\n"," [0. 0. 0. 1. 1. 1. 1. 1. 1.]\n"," [1. 1. 0. 0. 0. 0. 1. 0. 0.]]\n"]}],"source":["my_corpus = docs\n","my_vocab = list(vocab)     # convierto a lista para asegurar orden de los terminos\n","n_docs = len(my_corpus)\n","n_vocab = len(my_vocab)\n","print(my_corpus)\n","print(my_vocab)\n","\n","ohe = np.zeros(shape=(n_docs, n_vocab))\n","for j, term in enumerate(my_vocab):\n","    # para cada termino en mi vocabulario, busco si esta presente en cada documento\n","    for i in range(n_docs):\n","        ohe[i, j] = 1 if term in my_corpus[i] else 0\n","\n","print('Matriz de vectores One Hot Encoding:')\n","print(ohe)"]},{"cell_type":"markdown","metadata":{"id":"IIyWGmCpJVQL"},"source":["### 3- Vectores de frecuencia\n","Data una lista de textos, devolver una matriz con la representación de frecuencia de estos"]},{"cell_type":"code","execution_count":54,"metadata":{"id":"yqij_7eHJbUi"},"outputs":[{"name":"stdout","output_type":"stream","text":["[['que', 'dia', 'es', 'hoy'], ['martes', 'el', 'dia', 'de', 'hoy', 'es', 'martes'], ['martes', 'muchas', 'gracias']]\n","['muchas', 'gracias', 'que', 'es', 'de', 'hoy', 'martes', 'el', 'dia']\n","[[0. 0. 1. 1. 0. 1. 0. 0. 1.]\n"," [0. 0. 0. 1. 1. 1. 2. 1. 1.]\n"," [1. 1. 0. 0. 0. 0. 1. 0. 0.]]\n"]}],"source":["my_corpus = docs\n","my_vocab = list(vocab)     # convierto a lista para asegurar orden de los terminos\n","\n","n_docs = len(my_corpus)\n","n_vocab = len(my_vocab)\n","print(my_corpus)\n","print(my_vocab)\n","\n","freq_vector = np.zeros(shape=(n_docs, n_vocab))\n","for j, term in enumerate(my_vocab):\n","    for i in range(n_docs):\n","        freq_vector[i, j] = my_corpus[i].count(term)\n","\n","print('Matriz de vectores de frecuencia:')\n","print(freq_vector)"]},{"cell_type":"markdown","metadata":{"id":"z_Ot8HvWJcBu"},"source":["### 4- TF-IDF\n","Data una lista de textos, devolver una matriz con la representacion TFIDF"]},{"cell_type":"code","execution_count":89,"metadata":{"id":"waG_oWtpJjRw"},"outputs":[{"name":"stdout","output_type":"stream","text":["Matriz TF-IDF:\n","[[0.         0.         0.47712125 0.17609126 0.         0.17609126\n","  0.         0.         0.17609126]\n"," [0.         0.         0.         0.17609126 0.47712125 0.17609126\n","  0.35218252 0.47712125 0.17609126]\n"," [0.47712125 0.47712125 0.         0.         0.         0.\n","  0.17609126 0.         0.        ]]\n"]}],"source":["my_corpus = docs\n","my_vocab = list(vocab)     # convierto a lista para asegurar orden de los terminos\n","\n","n_docs = len(my_corpus)\n","n_vocab = len(my_vocab)\n","\n","# Creo un diccionario con el IDF de cada termino\n","idf_dict = dict()\n","for t in my_vocab:\n","    df = 0\n","    for doc in my_corpus:\n","        if t in doc:\n","            df += 1\n","    idf_dict[t] = np.log10(n_docs / df)\n","\n","# Ahora creo la tabla TFIDF\n","tfidf_matrix = np.zeros(shape=(n_docs, n_vocab))\n","for j, term in enumerate(my_vocab):\n","    for i in range(n_docs):\n","        tfidf_matrix[i, j] = my_corpus[i].count(term) * idf_dict[term]\n","print('Matriz TF-IDF:')\n","print(tfidf_matrix)\n"]},{"cell_type":"markdown","metadata":{"id":"xMcsfndWJjm_"},"source":["### 5 - Comparación de documentos\n","Realizar una funcion que reciba el corpus y el índice de un documento y devuelva los documentos ordenados por la similitud coseno"]},{"cell_type":"code","execution_count":94,"metadata":{"id":"CZdiop6IJpZN"},"outputs":[{"name":"stdout","output_type":"stream","text":["Vector de similitud coseno: [[0.2003419  1.         0.10845712]]\n","[1 0 2]\n","Vector de similitud coseno: [[0.61237244 1.         0.23570226]]\n","[1 0 2]\n","Vector de similitud coseno: [[0.5        1.         0.38490018]]\n","[1 0 2]\n"]}],"source":["# Esta funcion acepta como argumento una matriz de texto vectorizado y el indice de un documento de referencia. \n","# A partir del documento de referenciam, obtiene el vector (ya sea vector de frecuencia, one-hot encoding o TF-IDF), \n","# y computa la similitud coseno entre ese vector y el resto de los documentos. \n","# Devuelve un arreglo de indices de documentos, ordenados de mayor a menor similitud. El primer valor siempre será el\n","# valor ref_doc_index, ya que la similitud coseno de un documento consigo mismo siempre dará 1.\n","# Nota: No se computa la matriz de texto vectorizado en esta función para mantenerla lo más simple posible. Cómo obtener\n","# esta matriz ya se implementó en los ejercicios anteriores.\n","def ordenar_por_similitud_coseno(df, ref_doc_index):\n","    n_docs = df.shape[0]\n","    vector = np.zeros(shape=(1,n_docs))\n","    v1 = df[ref_doc_index, :]     # obtengo vector para del doc de referencia\n","    for other_doc_idx in range(n_docs):\n","        v2 = df[other_doc_idx, :]    # obtengo vector para doc a comparar\n","        vector[0,other_doc_idx] = cosine_similarity(v1, v2)\n","    print(f'Vector de similitud coseno: {vector}')\n","\n","    return np.argsort(-vector).flatten()  # devuelvo los indices en orden descendiente de similitud coseno\n","\n","# Vemos como se compara el resultado con cada tipo de matriz de vectores\n","print(ordenar_por_similitud_coseno(tfidf_matrix, 1))\n","print(ordenar_por_similitud_coseno(ohe, 1))\n","print(ordenar_por_similitud_coseno(freq_vector, 1))"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyO5fRYTpympAwJSVbric6dW","collapsed_sections":[],"name":"1a - word2vec.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":0}
