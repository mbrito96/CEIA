{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27719223",
   "metadata": {},
   "source": [
    "\n",
    "# Generacion de Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461d011d",
   "metadata": {},
   "source": [
    "\n",
    "Descargar el dataset **NASA Bearings** https://www.kaggle.com/datasets/vinayak123tyagi/bearing-dataset. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a976dd3",
   "metadata": {},
   "source": [
    "# Importar librerías\n",
    "\n",
    "Importar aquellas librerías que serán utilizadas en el trabajo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "845b6c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import skew, kurtosis\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import preprocessing\n",
    "import math\n",
    "from cmath import sqrt\n",
    "from fileinput import filename\n",
    "import os\n",
    "from os.path import isfile, join\n",
    "from matplotlib.pyplot import axis\n",
    "from numpy import divide\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954111ce",
   "metadata": {},
   "source": [
    "### Definición de funciones generadoras de features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26f41c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns of the dataset:  ['aMean_0', 'std_0', 'irq_0', 'skew_0', 'kurtosis_0', 'f0_0', 'Pf0_0', 'Xrms_0', 'zeroX_0', 'p2p_0', 'crest_0', 'clearance_0', 'shape_0', 'impulse_0', 'aMean_1', 'std_1', 'irq_1', 'skew_1', 'kurtosis_1', 'f0_1', 'Pf0_1', 'Xrms_1', 'zeroX_1', 'p2p_1', 'crest_1', 'clearance_1', 'shape_1', 'impulse_1', 'aMean_2', 'std_2', 'irq_2', 'skew_2', 'kurtosis_2', 'f0_2', 'Pf0_2', 'Xrms_2', 'zeroX_2', 'p2p_2', 'crest_2', 'clearance_2', 'shape_2', 'impulse_2', 'aMean_3', 'std_3', 'irq_3', 'skew_3', 'kurtosis_3', 'f0_3', 'Pf0_3', 'Xrms_3', 'zeroX_3', 'p2p_3', 'crest_3', 'clearance_3', 'shape_3', 'impulse_3', 'covar_01', 'covar_02', 'covar_03', 'covar_12', 'covar_13', 'covar_23']\n"
     ]
    }
   ],
   "source": [
    "# Define feature generating functions\n",
    "\n",
    "# onlyfiles = [f for f in listdir(PATH_EXPERIMENT) if isfile(join(PATH_EXPERIMENT, f))]\n",
    "single_features = {'aMean': True, 'std': True, 'irq': True, 'skew': True, 'kurtosis': True, 'f0': True, 'Pf0': True, 'Xrms': True, 'zeroX': True, 'p2p': True, 'crest': True, 'clearance': True, 'shape': True, 'impulse': True}    # List of features computed for single bearings\n",
    "multi_features = {'covar': True}   # List of features computed between bearings\n",
    "n_bearings = 4  # Number of bearings\n",
    "df_columns = []\n",
    "\n",
    "## Create list of feature names\n",
    "# Single channel\n",
    "for i in range(n_bearings):\n",
    "    for key in single_features.keys():\n",
    "        if(single_features[key] == True):\n",
    "            df_columns.append(key+'_'+str(i))\n",
    "# Multi channel\n",
    "for i in range(n_bearings):\n",
    "    for j in range(n_bearings):\n",
    "        if(i >= j):\n",
    "            continue\n",
    "        else:\n",
    "            for key in multi_features.keys():\n",
    "                if(multi_features[key] == True):\n",
    "                    df_columns.append(key+'_'+str(i)+str(j))\n",
    "\n",
    "\n",
    "print('Columns of the dataset: ', df_columns)\n",
    "\n",
    "def GetIQR(df):\n",
    "    q1 = df.quantile(0.25)\n",
    "    q3 = df.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    return np.array(iqr).flatten().reshape(1,4)\n",
    "\n",
    "# @param ignore_dc If True, the functions skips the first harmonic if it is DC frequency.\n",
    "# @return A list of 4 sublists, where the top n_harmonics for each bearing are stored in each sublist. Each harmonic is stored as a tuple (magnitude, frequency)\n",
    "def GetFundFreq(df, Fs, n_harmonics = 1, ignore_dc = False):\n",
    "    signal = np.array(df)\n",
    "    fft_abs = np.abs(np.fft.rfft(signal, axis=0))\n",
    "    freq = np.fft.rfftfreq(signal.shape[0], d=1/Fs)\n",
    "    harmonics = [] \n",
    "    for column in fft_abs.T:\n",
    "        # Get top N frequencies\n",
    "        fsorted = sorted(zip(column, freq), reverse=True)\n",
    "        skip = 0\n",
    "        if(ignore_dc and fsorted[0][1] == 0.0):\n",
    "            skip = 1\n",
    "        harmonics.append(fsorted[skip:n_harmonics+skip])\n",
    "    return harmonics\n",
    "\n",
    "def GetZeroCrossings(df_in):\n",
    "    crossings = []\n",
    "    for col in df_in.columns:\n",
    "        zero_crossings = np.where(np.diff(np.signbit(df_in[col])))[0]\n",
    "        crossings.append(len(zero_crossings))\n",
    "    return crossings\n",
    "\n",
    "def GetRMS(df_in):\n",
    "    pwr = []\n",
    "    length = df_in.shape[0]\n",
    "    for col in df_in.columns:\n",
    "        pwr.append(np.abs(np.sqrt(np.sum(np.square(df_in[col]))/length)))\n",
    "    return pwr\n",
    "\n",
    "\n",
    "def GetCovar(df_in):\n",
    "    covm = np.cov(df_in, rowvar=False)\n",
    "    # print('cov_01 | cov_02 | cov_03 | cov_12 | cov_13 | cov_23')\n",
    "    # print(covm[np.triu_indices(4,k=1)])\n",
    "    return covm[np.triu_indices(4,k=1)]\n",
    "\n",
    "def AddNewRow(df_out, df_in):\n",
    "    f_vals = np.empty((1,4))\n",
    "    abs_mean = np.array(df_in.abs().mean(axis=0)).flatten()\n",
    "    X_rms = GetRMS(df_in)    # Used for crest factor\n",
    "    # Get per bearing values\n",
    "    if(single_features['aMean']):   # Compute absolute mean for each channel\n",
    "        f_vals = np.vstack((f_vals, abs_mean))  # mean\n",
    "    if(single_features['std']):\n",
    "        f_vals = np.vstack((f_vals, np.array(df_in.std(axis=0)).flatten()))  # std\n",
    "    if(single_features['irq']):\n",
    "        f_vals = np.vstack((f_vals, GetIQR(df_in))) # irq\n",
    "    if(single_features['skew']):\n",
    "        f_vals = np.vstack((f_vals, skew(df_in, axis=0)))\n",
    "    if(single_features['kurtosis']):\n",
    "        f_vals = np.vstack((f_vals, kurtosis(df_in, axis=0)))\n",
    "    if(single_features['f0']):\n",
    "        freqs = GetFundFreq(df_in, 20000, n_harmonics=1, ignore_dc=True)\n",
    "        f_vals = np.vstack((f_vals, [i[0][1] for i in freqs]))\n",
    "        if(single_features['Pf0']):        # CHECK if getting the magnitude is ok. Should it be the magnitude squared??\n",
    "            f_vals = np.vstack((f_vals, [20*math.log10(i[0][0]) for i in freqs]))\n",
    "    if(single_features['Xrms']):\n",
    "        f_vals = np.vstack((f_vals, X_rms))\n",
    "    if(single_features['zeroX']):\n",
    "        f_vals = np.vstack((f_vals, GetZeroCrossings(df_in)))\n",
    "    if(single_features['p2p']):\n",
    "        peak_to_peak = np.array(np.abs(np.max(df_in, axis=0)) + np.abs(np.min(df_in, axis=0)))\n",
    "        f_vals = np.vstack((f_vals, peak_to_peak))\n",
    "    if(single_features['crest']):\n",
    "        crest = np.array(np.divide(np.max(df_in, axis=0),X_rms))\n",
    "        f_vals = np.vstack((f_vals, crest))\n",
    "    if(single_features['clearance']):\n",
    "        clearance = np.array(np.divide(np.max(df_in, axis=0), np.square(np.sum(np.sqrt(np.abs(df_in)), axis=0)/df_in.shape[0])))\n",
    "        f_vals = np.vstack((f_vals, clearance))\n",
    "    if(single_features['shape']):\n",
    "        shape = np.array(np.divide(X_rms, abs_mean))\n",
    "        f_vals = np.vstack((f_vals, shape))\n",
    "    if(single_features['impulse']):\n",
    "        impulse = np.array(np.divide(np.max(df_in, axis=0), abs_mean))\n",
    "        f_vals = np.vstack((f_vals, impulse))\n",
    "\n",
    "\n",
    "    f_vals = f_vals[1:] # Drop first row which is dummy\n",
    "    f_vals = f_vals.flatten(order='F')  # Merge rows into single row\n",
    "\n",
    "    # Now append crossfeatures\n",
    "    if(multi_features['covar']):\n",
    "        f_vals = np.append(f_vals, GetCovar(df_in))\n",
    "\n",
    "    new_row = pd.DataFrame(f_vals.reshape(1,len(df_columns)),columns=df_columns)\n",
    "    df_out = pd.concat([df_out, new_row], axis=0)\n",
    "    \n",
    "    return df_out\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668b55a3",
   "metadata": {},
   "source": [
    "### Cargo archivos del experimento de a uno y computo los features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8331ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    aMean_0     std_0  irq_0    skew_0 kurtosis_0        f0_0      Pf0_0  \\\n",
      "0  0.058332  0.073477  0.096  0.083993   0.628763  985.351562  52.733122   \n",
      "1  0.058997   0.07534  0.097  0.052142   0.648291  985.351562  51.201049   \n",
      "2  0.060239  0.076191    0.1  0.032808   0.513475  985.351562  50.779361   \n",
      "3  0.061453  0.078693    0.1  0.041486   1.157953  985.351562  51.079815   \n",
      "4  0.061361  0.078439  0.103  0.028224   0.603177  985.351562  50.279226   \n",
      "\n",
      "     Xrms_0 zeroX_0  p2p_0  ...   crest_3 clearance_3   shape_3  impulse_3  \\\n",
      "0  0.074179  6593.0   0.84  ...  3.567239    5.323107  1.256323   4.481604   \n",
      "1  0.075382  6867.0  0.757  ...  4.438435     6.64634  1.259563   5.590488   \n",
      "2   0.07623  6637.0  0.903  ...  6.305078    9.483004  1.263337   7.965439   \n",
      "3  0.078724  6659.0  1.184  ...  9.030509   13.503735  1.260116  11.379491   \n",
      "4  0.078474  6765.0  0.782  ...   4.29268    6.429704   1.25982   5.408004   \n",
      "\n",
      "   covar_01  covar_02  covar_03  covar_12  covar_13  covar_23  \n",
      "0  0.001398 -0.000501 -0.000304 -0.000295 -0.000837  0.000214  \n",
      "1  0.001287 -0.000289 -0.000188 -0.000216 -0.000852  0.000322  \n",
      "2  0.001349 -0.000503 -0.000284 -0.000487  -0.00103  0.000356  \n",
      "3   0.00141 -0.000455 -0.000221 -0.000525 -0.000961  0.000272  \n",
      "4  0.001668  -0.00051  -0.00031 -0.000548  -0.00105  0.000355  \n",
      "\n",
      "[5 rows x 62 columns]\n",
      "shape: (20, 62)\n"
     ]
    }
   ],
   "source": [
    "PATH_EXPERIMENT_2 = \"./archive/2nd_test/2nd_test/\"\n",
    "PATH_EXPERIMENT_3 = \"./archive/3rd_test/4th_test/txt/\"\n",
    "\n",
    "PATH_EXPERIMENT = PATH_EXPERIMENT_2\n",
    "\n",
    "files_to_process = 20 # if -1, process all files in path folder\n",
    "\n",
    "file_names = [x for x in os.listdir(PATH_EXPERIMENT)]# if x.endswith('.39')]\n",
    "df_in = None\n",
    "df_out = pd.DataFrame(columns=df_columns)#, 'std_0', 'std_1', 'std_2', 'std_3'])\n",
    "if(files_to_process == -1):\n",
    "    files_to_process = len(file_names)\n",
    "\n",
    "for i in range(files_to_process):\n",
    "    pathText = PATH_EXPERIMENT + '\\\\' + file_names[i]\n",
    "    df_in = pd.read_csv(pathText, delimiter='\\t', header=None)\n",
    "    df_out = AddNewRow(df_out, df_in)\n",
    "\n",
    "df_out=df_out.reset_index(inplace=False, drop=True)\n",
    "print(df_out.head())\n",
    "print(\"shape:\",df_out.shape)\n",
    "\n",
    "\n",
    "\n",
    "# Forma de nuestro dataset:\n",
    "# #sample | mean_0 | std_0 | .... | mean_1 | std_1 | ..... | mean_4 | std_4 | ... ||| failure_0 | failure_1 | ... | failure_3\n",
    "                                                                #                       None    | outer_race| ... | None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc9f00f",
   "metadata": {},
   "source": [
    "### Agrego columna target\n",
    "El usuario debe ingresar cuál rodamiento falló al final del experimento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9f75318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      aMean_0     std_0  irq_0    skew_0 kurtosis_0         f0_0      Pf0_0  \\\n",
      "0    0.058332  0.073477  0.096  0.083993   0.628763   985.351562  52.733122   \n",
      "1    0.058997   0.07534  0.097  0.052142   0.648291   985.351562  51.201049   \n",
      "2    0.060239  0.076191    0.1  0.032808   0.513475   985.351562  50.779361   \n",
      "3    0.061453  0.078693    0.1  0.041486   1.157953   985.351562  51.079815   \n",
      "4    0.061361  0.078439  0.103  0.028224   0.603177   985.351562  50.279226   \n",
      "..        ...       ...    ...       ...        ...          ...        ...   \n",
      "979  0.453318  0.725014   0.63 -0.510556  12.577705    4398.4375  65.182241   \n",
      "980  0.337575  0.462001  0.528 -0.325368   3.759972  4397.460938  62.634087   \n",
      "981  0.351094  0.483844  0.542 -0.377095   4.891755  4846.679688   60.05091   \n",
      "982  0.001857  0.000987    0.0  0.579698   3.637513     58.59375  15.223287   \n",
      "983  0.001168     0.001  0.002  0.317032  -1.609774     58.59375  18.504699   \n",
      "\n",
      "       Xrms_0 zeroX_0  p2p_0  ...  covar_01  covar_02  covar_03  covar_12  \\\n",
      "0    0.074179  6593.0   0.84  ...  0.001398 -0.000501 -0.000304 -0.000295   \n",
      "1    0.075382  6867.0  0.757  ...  0.001287 -0.000289 -0.000188 -0.000216   \n",
      "2     0.07623  6637.0  0.903  ...  0.001349 -0.000503 -0.000284 -0.000487   \n",
      "3    0.078724  6659.0  1.184  ...   0.00141 -0.000455 -0.000221 -0.000525   \n",
      "4    0.078474  6765.0  0.782  ...  0.001668  -0.00051  -0.00031 -0.000548   \n",
      "..        ...     ...    ...  ...       ...       ...       ...       ...   \n",
      "979  0.725001  7662.0  9.998  ... -0.004783  0.001412  0.012355 -0.012524   \n",
      "980  0.462012  8449.0  5.569  ... -0.009492  0.010375  0.011912 -0.007516   \n",
      "981  0.483835  8105.0  7.197  ... -0.003363  0.002693  0.002919 -0.010635   \n",
      "982  0.002103     0.0  0.005  ...  0.000001  0.000001       0.0  0.000001   \n",
      "983  0.001533  3610.0  0.007  ...  0.000001  0.000001  0.000001  0.000001   \n",
      "\n",
      "     covar_13  covar_23   y0   y1   y2   y3  \n",
      "0   -0.000837  0.000214  0.0  0.0  0.0  0.0  \n",
      "1   -0.000852  0.000322  0.0  0.0  0.0  0.0  \n",
      "2    -0.00103  0.000356  0.0  0.0  0.0  0.0  \n",
      "3   -0.000961  0.000272  0.0  0.0  0.0  0.0  \n",
      "4    -0.00105  0.000355  0.0  0.0  0.0  0.0  \n",
      "..        ...       ...  ...  ...  ...  ...  \n",
      "979 -0.006606  0.005868  0.0  0.0  0.0  0.0  \n",
      "980 -0.005103   0.00427  0.0  0.0  0.0  0.0  \n",
      "981 -0.005334  0.006466  0.0  0.0  0.0  0.0  \n",
      "982  0.000001  0.000001  0.0  0.0  0.0  0.0  \n",
      "983  0.000001  0.000001  1.0  0.0  0.0  0.0  \n",
      "\n",
      "[984 rows x 66 columns]\n"
     ]
    }
   ],
   "source": [
    "# Add target columns\n",
    "from numpy import zeros\n",
    "\n",
    "bearing_that_failed = 1 # Bearing: 1 - 4\n",
    "\n",
    "results = np.array([zeros((df_out.shape[0])) for i in range(n_bearings)]).T\n",
    "results[-1][bearing_that_failed-1] = 1  # Bearing that failed at the end\n",
    "pd_results = pd.DataFrame(data=results, columns=['y0', 'y1', 'y2', 'y3'])\n",
    "df_out = pd.concat([df_out, pd_results], axis=1)\n",
    "print(df_out.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9eebc1",
   "metadata": {},
   "source": [
    "### Exportar a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "195153dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "PATH_DATASET = \"./dataset02.csv\"\n",
    "df_out.to_csv(PATH_DATASET, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "54dee8e2628c7a348348274027baca590104374d7a70a03370ff5ec22cf94c02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
