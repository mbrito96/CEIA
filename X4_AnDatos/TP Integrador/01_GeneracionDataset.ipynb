{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27719223",
   "metadata": {},
   "source": [
    "\n",
    "# Generacion de Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461d011d",
   "metadata": {},
   "source": [
    "\n",
    "Descargar el dataset **Facebook comment volume** https://archive.ics.uci.edu/ml/datasets/Facebook+Comment+Volume+Dataset. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a976dd3",
   "metadata": {},
   "source": [
    "# Importar librerías\n",
    "\n",
    "Importar aquellas librerías que serán utilizadas en el trabajo.\n",
    "\n",
    "$$P_{rms}=\\sqrt{\\frac{1}{N}\\sum\\limits_{i=N}^N {x(i)}^2} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "845b6c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import skew, kurtosis\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954111ce",
   "metadata": {},
   "source": [
    "# Cargar datos\n",
    "Cargar los datos de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "26f41c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns of the dataset:  ['mean_0', 'std_0', 'f0_0', 'zero_cross_0', 'mean_1', 'std_1', 'f0_1', 'zero_cross_1', 'mean_2', 'std_2', 'f0_2', 'zero_cross_2', 'mean_3', 'std_3', 'f0_3', 'zero_cross_3']\n",
      "     mean_0     std_0        f0_0 zero_cross_0    mean_1     std_1  \\\n",
      "0 -0.010196  0.073477  985.351562       6593.0 -0.012695  0.090056   \n",
      "\n",
      "         f0_1 zero_cross_1    mean_2     std_2        f0_2 zero_cross_2  \\\n",
      "0  985.351562       7255.0 -0.014541  0.108436  985.351562       8758.0   \n",
      "\n",
      "     mean_3     std_3        f0_3 zero_cross_3  \n",
      "0 -0.010026  0.053168  985.351562       6446.0  \n",
      "shape: (1, 16)\n"
     ]
    }
   ],
   "source": [
    "PATH_EXPERIMENT = \"./archive/2nd_test/2nd_test/\"\n",
    "PATH_DATASET = \"./Dataset/dataset_2.csv\"\n",
    "\n",
    "from fileinput import filename\n",
    "import os\n",
    "from os.path import isfile, join\n",
    "from matplotlib.pyplot import axis\n",
    "\n",
    "# onlyfiles = [f for f in listdir(PATH_EXPERIMENT) if isfile(join(PATH_EXPERIMENT, f))]\n",
    "single_features = {'mean': True, 'std': True, 'irq': False, 'skew': False, 'kurtosis': False, 'f0': True, 'P_f0': False, 'P_rms': False, 'zero_cross': True }    # List of features computed for single bearings\n",
    "multi_features = {'covar': False, 'autocor': False}   # List of features computed between bearings\n",
    "n_bearings = 4  # Number of bearings\n",
    "df_columns = []\n",
    "\n",
    "## Create list of feature names\n",
    "# Single channel\n",
    "for i in range(n_bearings):\n",
    "    for key in single_features.keys():\n",
    "        if(single_features[key] == True):\n",
    "            df_columns.append(key+'_'+str(i))\n",
    "# Multi channel\n",
    "for i in range(n_bearings):\n",
    "    for j in range(n_bearings):\n",
    "        if(i >= j):\n",
    "            continue\n",
    "        else:\n",
    "            for key in multi_features.keys():\n",
    "                if(multi_features[key] == True):\n",
    "                    df_columns.append(key+'_'+str(i)+str(j))\n",
    "\n",
    "\n",
    "print('Columns of the dataset: ', df_columns)\n",
    "\n",
    "def GetIQR(df):\n",
    "    q1 = df.quantile(0.25)\n",
    "    q3 = df.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    return np.array(iqr).flatten().reshape(1,4)\n",
    "\n",
    "# @param ignore_dc If True, the functions skips the first harmonic if it is DC frequency.\n",
    "# @return A list of 4 sublists, where the top n_harmonics for each bearing are stored in each sublist. Each harmonic is stored as a tuple (magnitude, frequency)\n",
    "def GetFundFreq(df, Fs, n_harmonics = 1, ignore_dc = False):\n",
    "    signal = np.array(df)\n",
    "    fft_abs = np.abs(np.fft.rfft(signal, axis=0))\n",
    "    freq = np.fft.rfftfreq(signal.shape[0], d=1/Fs)\n",
    "    harmonics = [] \n",
    "    for column in fft_abs.T:\n",
    "        # Get top N frequencies\n",
    "        fsorted = sorted(zip(column, freq), reverse=True)\n",
    "        skip = 0\n",
    "        if(ignore_dc and fsorted[0][1] == 0.0):\n",
    "            skip = 1\n",
    "        harmonics.append(fsorted[skip:n_harmonics+skip])\n",
    "    return harmonics\n",
    "\n",
    "def GetZeroCrossings(df_in):\n",
    "    crossings = []\n",
    "    for col in df_in.columns:\n",
    "        zero_crossings = np.where(np.diff(np.signbit(df_in[col])))[0]\n",
    "        crossings.append(len(zero_crossings))\n",
    "    return crossings\n",
    "\n",
    "    \n",
    "\n",
    "def AddNewRow(df_out, df_in):\n",
    "    # Get per bearing values\n",
    "    f_vals = np.empty((1,4))\n",
    "\n",
    "    if(single_features['mean']):\n",
    "        f_vals = np.vstack((f_vals, np.array(df_in.mean(axis=0)).reshape(1,4)))  # mean\n",
    "    if(single_features['std']):\n",
    "        f_vals = np.vstack((f_vals, np.array(df_in.std(axis=0)).reshape(1,4)))  # std\n",
    "    if(single_features['irq']):\n",
    "        f_vals = np.vstack((f_vals, GetIQR(df_in))) # irq\n",
    "    if(single_features['skew']):\n",
    "        f_vals = np.vstack((f_vals, skew(df_in, axis=0)))\n",
    "    if(single_features['kurtosis']):\n",
    "        f_vals = np.vstack((f_vals, kurtosis(df_in, axis=0)))\n",
    "    if(single_features['f0']):\n",
    "        freqs = GetFundFreq(df_in, 20000, n_harmonics=1, ignore_dc=True)\n",
    "        f_vals = np.vstack((f_vals, [i[0][1] for i in freqs]))\n",
    "        if(single_features['P_f0']):        # CHECK if getting the magnitude is ok. Should it be the magnitude squared??\n",
    "            f_vals = np.vstack((f_vals, [i[0][0] for i in freqs]))\n",
    "    if(single_features['P_rms']):\n",
    "        pass\n",
    "    if(single_features['zero_cross']):\n",
    "        f_vals = np.vstack((f_vals, GetZeroCrossings(df_in)))\n",
    "    if(multi_features['covar']):\n",
    "        pass\n",
    "    if(multi_features['autocor']):\n",
    "        pass\n",
    "\n",
    "    f_vals = f_vals[1:] # Drop first row which is dummy\n",
    "    new_row = pd.DataFrame(f_vals.flatten(order='F').reshape(1,len(df_columns)),columns=df_columns)\n",
    "\n",
    "    # Get \n",
    "\n",
    "    df_out = pd.concat([df_out, new_row], axis=0)\n",
    "    \n",
    "    return df_out\n",
    "    \n",
    "\n",
    "\n",
    "files_to_process = 1 # if -1, process all files in path folder\n",
    "\n",
    "file_names = [x for x in os.listdir(PATH_EXPERIMENT) if x.endswith('.39')]\n",
    "df_in = None\n",
    "df_out = pd.DataFrame(columns=df_columns)#, 'std_0', 'std_1', 'std_2', 'std_3'])\n",
    "if(files_to_process == -1):\n",
    "    files_to_process = len(file_names)\n",
    "\n",
    "for i in range(files_to_process):\n",
    "    pathText = PATH_EXPERIMENT + '\\\\' + file_names[i]\n",
    "    df_in = pd.read_csv(pathText, delimiter='\\t', header=None)\n",
    "    df_out = AddNewRow(df_out, df_in)\n",
    "\n",
    "df_out=df_out.reset_index(inplace=False, drop=True)\n",
    "print(df_out.head())\n",
    "print(\"shape:\",df_out.shape)\n",
    "\n",
    "\n",
    "\n",
    "# Forma de nuestro dataset:\n",
    "# #sample | mean_0 | std_0 | .... | mean_1 | std_1 | ..... | mean_4 | std_4 | ... ||| failure_0 | failure_1 | ... | failure_3\n",
    "                                                                #                       None    | outer_race| ... | None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "04f3f724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 [1 2 3 4 5]\n",
      "2 [0 2]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as plt\n",
    "\n",
    "def GetFundFreq(df, Fs):\n",
    "    signal = np.array(df)\n",
    "    fft_abs = np.abs(np.fft.rfft(signal, axis=0))\n",
    "    freq = np.fft.rfftfreq(signal.shape[0], d=1/Fs)\n",
    "    i = 1\n",
    "    harmonics_to_get = 6\n",
    "    harmonics = []\n",
    "    fig = plt.figure()\n",
    "    fig2 = plt.figure()\n",
    "    axes_top = fig2.add_axes([0, 0, 1.2, 1.2])\n",
    "    for column in fft_abs.T:\n",
    "        axes = fig.add_axes([i, 0, 0.8, 1.2])\n",
    "        axes.set_xlabel(\"frequency, Hz\")\n",
    "        axes.set_ylabel(\"Amplitude, units\")\n",
    "        axes.plot(freq, column)\n",
    "        i+=1\n",
    "        # Get top N frequencies\n",
    "        harmonics.append(sorted(zip(column, freq), reverse=True)[:harmonics_to_get])\n",
    "        one = np.asarray(harmonics[-1]).T\n",
    "        axes_top.scatter(one[:][1], one[:][0] )\n",
    "    plt.show()\n",
    "    # print(harmonics)\n",
    "    # one = np.asarray(harmonics[0]).T\n",
    "    # two = np.asarray(harmonics[1]).T\n",
    "    # fig = plt.figure()\n",
    "    # axes = fig.add_axes([0, 0, 1.2, 1.2])\n",
    "    # axes.scatter(one[:][1], one[:][0] )\n",
    "    # axes.scatter(two[:][1], two[:][0] )\n",
    "    \n",
    "\n",
    "# GetFundFreq(df_in, 20000)\n",
    "\n",
    "test = np.array([[0, 1,-1,1,-1,1,-1],[0, -2, -1, 0, 1, 2, 0]])\n",
    "for i in test:\n",
    "    zero_crossings = np.where(np.diff(np.signbit(i)))[0]\n",
    "    print(len(zero_crossings), zero_crossings)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "54dee8e2628c7a348348274027baca590104374d7a70a03370ff5ec22cf94c02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
