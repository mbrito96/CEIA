{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27719223",
   "metadata": {},
   "source": [
    "\n",
    "# Generacion de Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461d011d",
   "metadata": {},
   "source": [
    "\n",
    "Descargar el dataset **Facebook comment volume** https://archive.ics.uci.edu/ml/datasets/Facebook+Comment+Volume+Dataset. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a976dd3",
   "metadata": {},
   "source": [
    "# Importar librerías\n",
    "\n",
    "Importar aquellas librerías que serán utilizadas en el trabajo.\n",
    "\n",
    "$$P_{rms}=\\sqrt{\\frac{1}{N}\\sum\\limits_{i=N}^N {x(i)}^2} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "845b6c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import skew, kurtosis\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import preprocessing\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954111ce",
   "metadata": {},
   "source": [
    "# Cargar datos\n",
    "Cargar los datos de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "26f41c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns of the dataset:  ['aMean_0', 'Xrms_0', 'aMean_1', 'Xrms_1', 'aMean_2', 'Xrms_2', 'aMean_3', 'Xrms_3']\n",
      "[0.07417899856512623] 0.07417899856512623\n",
      "[0.07417899856512623, 0.09094388696428075] 0.09094388696428075\n",
      "[0.07417899856512623, 0.09094388696428075, 0.10940413919878957] 0.10940413919878957\n",
      "[0.07417899856512623, 0.09094388696428075, 0.10940413919878957, 0.05410346803954669] 0.05410346803954669\n",
      "    aMean_0    Xrms_0   aMean_1    Xrms_1   aMean_2    Xrms_2   aMean_3  \\\n",
      "0  0.058332  0.074179  0.071832  0.090944  0.083244  0.109404  0.043065   \n",
      "\n",
      "     Xrms_3  \n",
      "0  0.054103  \n",
      "shape: (1, 8)\n"
     ]
    }
   ],
   "source": [
    "PATH_EXPERIMENT = \"./archive/2nd_test/2nd_test/\"\n",
    "PATH_DATASET = \"./Dataset/dataset_2.csv\"\n",
    "\n",
    "from cmath import sqrt\n",
    "from fileinput import filename\n",
    "import os\n",
    "from os.path import isfile, join\n",
    "from matplotlib.pyplot import axis\n",
    "from numpy import divide\n",
    "\n",
    "# onlyfiles = [f for f in listdir(PATH_EXPERIMENT) if isfile(join(PATH_EXPERIMENT, f))]\n",
    "single_features = {'aMean': True, 'std': False, 'irq': False, 'skew': False, 'kurtosis': False, 'f0': False, 'Pf0': False, 'Xrms': True, 'zeroX': False, 'p2p': False, 'crest': False, 'clearance': False, 'shape': False, 'impulse': False}    # List of features computed for single bearings\n",
    "multi_features = {'covar': False, 'autocor': False}   # List of features computed between bearings\n",
    "n_bearings = 4  # Number of bearings\n",
    "df_columns = []\n",
    "\n",
    "## Create list of feature names\n",
    "# Single channel\n",
    "for i in range(n_bearings):\n",
    "    for key in single_features.keys():\n",
    "        if(single_features[key] == True):\n",
    "            df_columns.append(key+'_'+str(i))\n",
    "# Multi channel\n",
    "for i in range(n_bearings):\n",
    "    for j in range(n_bearings):\n",
    "        if(i >= j):\n",
    "            continue\n",
    "        else:\n",
    "            for key in multi_features.keys():\n",
    "                if(multi_features[key] == True):\n",
    "                    df_columns.append(key+'_'+str(i)+str(j))\n",
    "\n",
    "\n",
    "print('Columns of the dataset: ', df_columns)\n",
    "\n",
    "def GetIQR(df):\n",
    "    q1 = df.quantile(0.25)\n",
    "    q3 = df.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    return np.array(iqr).flatten().reshape(1,4)\n",
    "\n",
    "# @param ignore_dc If True, the functions skips the first harmonic if it is DC frequency.\n",
    "# @return A list of 4 sublists, where the top n_harmonics for each bearing are stored in each sublist. Each harmonic is stored as a tuple (magnitude, frequency)\n",
    "def GetFundFreq(df, Fs, n_harmonics = 1, ignore_dc = False):\n",
    "    signal = np.array(df)\n",
    "    fft_abs = np.abs(np.fft.rfft(signal, axis=0))\n",
    "    freq = np.fft.rfftfreq(signal.shape[0], d=1/Fs)\n",
    "    harmonics = [] \n",
    "    for column in fft_abs.T:\n",
    "        # Get top N frequencies\n",
    "        fsorted = sorted(zip(column, freq), reverse=True)\n",
    "        skip = 0\n",
    "        if(ignore_dc and fsorted[0][1] == 0.0):\n",
    "            skip = 1\n",
    "        harmonics.append(fsorted[skip:n_harmonics+skip])\n",
    "    return harmonics\n",
    "\n",
    "def GetZeroCrossings(df_in):\n",
    "    crossings = []\n",
    "    for col in df_in.columns:\n",
    "        zero_crossings = np.where(np.diff(np.signbit(df_in[col])))[0]\n",
    "        crossings.append(len(zero_crossings))\n",
    "    return crossings\n",
    "\n",
    "def GetRMS(df_in):\n",
    "    pwr = []\n",
    "    length = df_in.shape[0]\n",
    "    for col in df_in.columns:\n",
    "        pwr.append(np.abs(np.sqrt(np.sum(np.square(df_in[col]))/length)))\n",
    "    return pwr\n",
    "    \n",
    "\n",
    "\n",
    "def GetCovar(df_in):\n",
    "    covm = np.cov(df_in, rowvar=False)\n",
    "    # print('cov_01 | cov_02 | cov_03 | cov_12 | cov_13 | cov_23')\n",
    "    # print(covm[np.triu_indices(4,k=1)])\n",
    "    return covm[np.triu_indices(4,k=1)]\n",
    "\n",
    "def AddNewRow(df_out, df_in):\n",
    "    f_vals = np.empty((1,4))\n",
    "    abs_mean = np.array(df_in.abs().mean(axis=0)).flatten()\n",
    "    X_rms = GetRMS(df_in)    # Used for crest factor\n",
    "    # Get per bearing values\n",
    "    if(single_features['aMean']):   # Compute absolute mean for each channel\n",
    "        f_vals = np.vstack((f_vals, abs_mean))  # mean\n",
    "    if(single_features['std']):\n",
    "        f_vals = np.vstack((f_vals, np.array(df_in.std(axis=0)).flatten()))  # std\n",
    "    if(single_features['irq']):\n",
    "        f_vals = np.vstack((f_vals, GetIQR(df_in))) # irq\n",
    "    if(single_features['skew']):\n",
    "        f_vals = np.vstack((f_vals, skew(df_in, axis=0)))\n",
    "    if(single_features['kurtosis']):\n",
    "        f_vals = np.vstack((f_vals, kurtosis(df_in, axis=0)))\n",
    "    if(single_features['f0']):\n",
    "        freqs = GetFundFreq(df_in, 20000, n_harmonics=1, ignore_dc=True)\n",
    "        f_vals = np.vstack((f_vals, [i[0][1] for i in freqs]))\n",
    "        if(single_features['Pf0']):        # CHECK if getting the magnitude is ok. Should it be the magnitude squared??\n",
    "            f_vals = np.vstack((f_vals, [20*math.log10(i[0][0]) for i in freqs]))\n",
    "    if(single_features['Xrms']):\n",
    "        f_vals = np.vstack((f_vals, X_rms))\n",
    "    if(single_features['zeroX']):\n",
    "        f_vals = np.vstack((f_vals, GetZeroCrossings(df_in)))\n",
    "    if(single_features['p2p']):\n",
    "        peak_to_peak = np.array(np.abs(np.max(df_in, axis=0)) + np.abs(np.min(df_in, axis=0)))\n",
    "        f_vals = np.vstack((f_vals, peak_to_peak))\n",
    "    if(single_features['crest']):\n",
    "        crest = np.array(np.divide(np.max(df_in, axis=0),X_rms))\n",
    "        f_vals = np.vstack((f_vals, crest))\n",
    "    if(single_features['clearance']):\n",
    "        clearance = np.array(np.divide(np.max(df_in), np.square(np.sum(np.sqrt(np.abs(df_in)), axis=0)/df_in.shape[0])))\n",
    "        f_vals = np.vstack((f_vals, clearance))\n",
    "    if(single_features['shape']):\n",
    "        shape = np.array(np.divide(X_rms, abs_mean))\n",
    "        f_vals = np.vstack((f_vals, shape))\n",
    "    if(single_features['impulse']):\n",
    "        impulse = np.array(np.divide(np.max(df_in, axis=0), abs_mean))\n",
    "        f_vals = np.vstack((f_vals, impulse))\n",
    "\n",
    "\n",
    "    f_vals = f_vals[1:] # Drop first row which is dummy\n",
    "    f_vals = f_vals.flatten(order='F')  # Merge rows into single row\n",
    "\n",
    "    # Now append crossfeatures\n",
    "    if(multi_features['covar']):\n",
    "        f_vals = np.append(f_vals, GetCovar(df_in))\n",
    "    if(multi_features['autocor']):\n",
    "        pass\n",
    "\n",
    "    new_row = pd.DataFrame(f_vals.reshape(1,len(df_columns)),columns=df_columns)\n",
    "    df_out = pd.concat([df_out, new_row], axis=0)\n",
    "    \n",
    "    return df_out\n",
    "    \n",
    "\n",
    "\n",
    "files_to_process = 1 # if -1, process all files in path folder\n",
    "\n",
    "file_names = [x for x in os.listdir(PATH_EXPERIMENT) if x.endswith('.39')]\n",
    "df_in = None\n",
    "df_out = pd.DataFrame(columns=df_columns)#, 'std_0', 'std_1', 'std_2', 'std_3'])\n",
    "if(files_to_process == -1):\n",
    "    files_to_process = len(file_names)\n",
    "\n",
    "for i in range(files_to_process):\n",
    "    pathText = PATH_EXPERIMENT + '\\\\' + file_names[i]\n",
    "    df_in = pd.read_csv(pathText, delimiter='\\t', header=None)\n",
    "    df_out = AddNewRow(df_out, df_in)\n",
    "\n",
    "df_out=df_out.reset_index(inplace=False, drop=True)\n",
    "print(df_out.head())\n",
    "print(\"shape:\",df_out.shape)\n",
    "\n",
    "\n",
    "\n",
    "# Forma de nuestro dataset:\n",
    "# #sample | mean_0 | std_0 | .... | mean_1 | std_1 | ..... | mean_4 | std_4 | ... ||| failure_0 | failure_1 | ... | failure_3\n",
    "                                                                #                       None    | outer_race| ... | None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04f3f724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as plt\n",
    "\n",
    "def GetFundFreq(df, Fs):\n",
    "    signal = np.array(df)\n",
    "    fft_abs = np.abs(np.fft.rfft(signal, axis=0))\n",
    "    freq = np.fft.rfftfreq(signal.shape[0], d=1/Fs)\n",
    "    i = 1\n",
    "    harmonics_to_get = 6\n",
    "    harmonics = []\n",
    "    fig = plt.figure()\n",
    "    fig2 = plt.figure()\n",
    "    axes_top = fig2.add_axes([0, 0, 1.2, 1.2])\n",
    "    for column in fft_abs.T:\n",
    "        axes = fig.add_axes([i, 0, 0.8, 1.2])\n",
    "        axes.set_xlabel(\"frequency, Hz\")\n",
    "        axes.set_ylabel(\"Amplitude, units\")\n",
    "        axes.plot(freq, column)\n",
    "        i+=1\n",
    "        # Get top N frequencies\n",
    "        harmonics.append(sorted(zip(column, freq), reverse=True)[:harmonics_to_get])\n",
    "        one = np.asarray(harmonics[-1]).T\n",
    "        axes_top.scatter(one[:][1], one[:][0] )\n",
    "    plt.show()\n",
    "    # print(harmonics)\n",
    "    # one = np.asarray(harmonics[0]).T\n",
    "    # two = np.asarray(harmonics[1]).T\n",
    "    # fig = plt.figure()\n",
    "    # axes = fig.add_axes([0, 0, 1.2, 1.2])\n",
    "    # axes.scatter(one[:][1], one[:][0] )\n",
    "    # axes.scatter(two[:][1], two[:][0] )\n",
    "    \n",
    "\n",
    "# GetFundFreq(df_in, 20000)\n",
    "\n",
    "test = np.array([[0, 1,2, 3],[1,2,3,3]])\n",
    "val = 0\n",
    "for i in test:\n",
    "    val = np.sum(np.square(i))\n",
    "print(val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "54dee8e2628c7a348348274027baca590104374d7a70a03370ff5ec22cf94c02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
